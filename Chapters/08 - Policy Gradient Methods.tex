\chapter{Policy Gradient Methods}
Until now we have discussed so-called \textbf{action-value methods}, in which we learn the action values and use a policy (e.g., $\varepsilon$-greedy) to select actions based on those estimates. A possible alternative would be to have a different set of methods that could learn a \textbf{parametrized policy that can select actions without consulting a value function} (a value function might be used to learn the policy parameter, but it is not required for action selection).